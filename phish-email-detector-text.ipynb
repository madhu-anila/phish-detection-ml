{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff548ef-2b2c-4a7c-bb36-60e5cefe3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load each dataset\n",
    "datasets = {\n",
    "    'CEAS_08': pd.read_csv('ceas_08.csv'),\n",
    "    'enron': pd.read_csv('enron.csv'),\n",
    "    'ling': pd.read_csv('ling.csv'),\n",
    "    'nazario': pd.read_csv('nazario.csv'),\n",
    "    'Nigerian_Fraud': pd.read_csv('nigerian_fraud.csv'),\n",
    "    # 'SpamAssassin': pd.read_csv('spamassassin.csv')\n",
    "}\n",
    "\n",
    "# Standardize each dataset\n",
    "def standardize_dataset(df, source_name):\n",
    "    standardized = pd.DataFrame()\n",
    "    \n",
    "    # Map to common schema\n",
    "    standardized['subject'] = df.get('subject', '')\n",
    "    standardized['body'] = df.get('body', '')\n",
    "    standardized['label'] = df['label']\n",
    "    standardized['sender'] = df.get('sender', None)\n",
    "    standardized['receiver'] = df.get('receiver', None)\n",
    "    standardized['date'] = df.get('date', None)\n",
    "    standardized['urls'] = df.get('urls', None)\n",
    "    standardized['source'] = source_name\n",
    "    \n",
    "    return standardized\n",
    "\n",
    "# Combine all datasets\n",
    "combined_df = pd.concat([\n",
    "    standardize_dataset(df, name) \n",
    "    for name, df in datasets.items()\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd80066-5969-436f-8b86-5e4725cc7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject         0\n",
      "body            0\n",
      "label           0\n",
      "sender      32957\n",
      "receiver    34508\n",
      "date        33109\n",
      "urls        32626\n",
      "source          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing text fields with empty strings\n",
    "combined_df['subject'] = combined_df['subject'].fillna('')\n",
    "combined_df['body'] = combined_df['body'].fillna('')\n",
    "\n",
    "# Check completeness\n",
    "print(combined_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68194236-18f9-4e6b-b798-5713e0947c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove HTML tags (common in emails)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Handle special characters (optional - depends on your model)\n",
    "    # text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "combined_df['subject_clean'] = combined_df['subject'].apply(clean_text)\n",
    "combined_df['body_clean'] = combined_df['body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7180912-ef3a-4e51-bcf1-81c4a1616b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for exact duplicates\n",
    "print(f\"Duplicates: {combined_df.duplicated(subset=['subject', 'body']).sum()}\")\n",
    "\n",
    "# Remove duplicates\n",
    "combined_df = combined_df.drop_duplicates(subset=['subject', 'body'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87278a67-b33f-4d73-bacb-899ea5e5f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize date format\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1caf6583-5397-486c-aa1b-92f804f0b6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    41173\n",
      "0    35504\n",
      "Name: count, dtype: int64\n",
      "source          label\n",
      "CEAS_08         0        17312\n",
      "                1        21842\n",
      "Nigerian_Fraud  1         3332\n",
      "enron           0        15791\n",
      "                1        13976\n",
      "ling            0         2401\n",
      "                1          458\n",
      "nazario         1         1565\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_df['label'].value_counts())\n",
    "print(combined_df.groupby(['source', 'label']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f463be7b-72f6-4380-b055-abd704d6bb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">subject_length</th>\n",
       "      <th colspan=\"8\" halign=\"left\">body_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35504.0</td>\n",
       "      <td>39.262984</td>\n",
       "      <td>22.721899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>35504.0</td>\n",
       "      <td>2174.392068</td>\n",
       "      <td>5178.198201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>2186.25</td>\n",
       "      <td>230120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41173.0</td>\n",
       "      <td>33.307313</td>\n",
       "      <td>43.032401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7170.0</td>\n",
       "      <td>41173.0</td>\n",
       "      <td>1312.297817</td>\n",
       "      <td>23290.751224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1368.00</td>\n",
       "      <td>4599644.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject_length                                                       \\\n",
       "               count       mean        std  min   25%   50%   75%     max   \n",
       "label                                                                       \n",
       "0            35504.0  39.262984  22.721899  0.0  24.0  36.0  50.0   815.0   \n",
       "1            41173.0  33.307313  43.032401  0.0  20.0  29.0  42.0  7170.0   \n",
       "\n",
       "      body_length                                                          \\\n",
       "            count         mean           std  min    25%     50%      75%   \n",
       "label                                                                       \n",
       "0         35504.0  2174.392068   5178.198201  1.0  526.0  1088.0  2186.25   \n",
       "1         41173.0  1312.297817  23290.751224  1.0  204.0   442.0  1368.00   \n",
       "\n",
       "                  \n",
       "             max  \n",
       "label             \n",
       "0       230120.0  \n",
       "1      4599644.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['subject_length'] = combined_df['subject'].str.len()\n",
    "combined_df['body_length'] = combined_df['body'].str.len()\n",
    "\n",
    "# Compare lengths by label\n",
    "combined_df.groupby('label')[['subject_length', 'body_length']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ae1758-c8d9-4310-b213-404e7356741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty records: 0\n"
     ]
    }
   ],
   "source": [
    "# Find records with empty subject AND body\n",
    "empty_records = combined_df[\n",
    "    (combined_df['subject'].str.len() == 0) & \n",
    "    (combined_df['body'].str.len() == 0)\n",
    "]\n",
    "print(f\"Empty records: {len(empty_records)}\")\n",
    "\n",
    "# Remove them\n",
    "combined_df = combined_df[\n",
    "    (combined_df['subject'].str.len() > 0) | \n",
    "    (combined_df['body'].str.len() > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca6b261-4ecd-4c85-a0e5-5b0b01b40e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_records': 76677, 'phishing_count': np.int64(41173), 'legitimate_count': np.int64(35504), 'sources': {'CEAS_08': 39154, 'enron': 29767, 'Nigerian_Fraud': 3332, 'ling': 2859, 'nazario': 1565}}\n"
     ]
    }
   ],
   "source": [
    "# Save for modeling\n",
    "combined_df.to_csv('cleaned_combined_emails.csv', index=False)\n",
    "\n",
    "# Create a summary report\n",
    "summary = {\n",
    "    'total_records': len(combined_df),\n",
    "    'phishing_count': (combined_df['label'] == 1).sum(),\n",
    "    'legitimate_count': (combined_df['label'] == 0).sum(),\n",
    "    'sources': combined_df['source'].value_counts().to_dict()\n",
    "}\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429232a7-132e-4195-a82c-811f48626f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subject and body for text analysis\n",
    "combined_df['full_text'] = combined_df['subject'] + ' ' + combined_df['body']\n",
    "\n",
    "# OR keep them separate and concatenate their features later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a258b4b0-569b-4c44-94a2-4962189d99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limit to top 5000 words\n",
    "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
    "    min_df=5,  # Ignore rare words\n",
    "    max_df=0.8  # Ignore very common words\n",
    ")\n",
    "\n",
    "X_text = vectorizer.fit_transform(combined_df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12d4cf0b-5245-4bd3-ab03-eb2573a86ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sender_has_domain  sender_is_freemail  has_receiver  subject_length  \\\n",
      "0                  1                   0             1              25   \n",
      "1                  1                   0             1              22   \n",
      "2                  1                   0             1              20   \n",
      "3                  1                   0             1             150   \n",
      "4                  1                   0             1              26   \n",
      "\n",
      "   body_length  subject_word_count  body_word_count  url_count  has_urls  \\\n",
      "0          273                   6               46          0         0   \n",
      "1           82                   3                9          0         0   \n",
      "2         3918                   4              302          0         0   \n",
      "3        24418                  10             2660          0         0   \n",
      "4          175                   1                2          0         0   \n",
      "\n",
      "   suspicious_tld  subject_caps_ratio  subject_exclamation  body_exclamation  \\\n",
      "0               0            0.040000                    0                 2   \n",
      "1               0            0.136364                    0                 0   \n",
      "2               0            0.250000                    0                 0   \n",
      "3               0            0.086667                    0                 4   \n",
      "4               0            0.153846                    0                 0   \n",
      "\n",
      "   has_dollar_sign  phishing_keyword_count  hour_of_day  day_of_week  \\\n",
      "0                0                       0           16            1   \n",
      "1                0                       0           -1           -1   \n",
      "2                0                       0           -1           -1   \n",
      "3                1                       1           -1           -1   \n",
      "4                0                       0           -1           -1   \n",
      "\n",
      "   is_weekend  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "\n",
      "Feature shape: (76677, 18)\n",
      "\n",
      "Feature columns: ['sender_has_domain', 'sender_is_freemail', 'has_receiver', 'subject_length', 'body_length', 'subject_word_count', 'body_word_count', 'url_count', 'has_urls', 'suspicious_tld', 'subject_caps_ratio', 'subject_exclamation', 'body_exclamation', 'has_dollar_sign', 'phishing_keyword_count', 'hour_of_day', 'day_of_week', 'is_weekend']\n",
      "\n",
      "Any NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # === EMAIL METADATA FEATURES ===\n",
    "    \n",
    "    # Sender domain features (handle NaN)\n",
    "    features['sender_has_domain'] = df['sender'].notna().astype(int)\n",
    "    features['sender_is_freemail'] = df['sender'].fillna('').astype(str).str.contains(\n",
    "        '@gmail|@yahoo|@hotmail|@outlook', \n",
    "        case=False, regex=True\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Receiver features\n",
    "    features['has_receiver'] = df['receiver'].notna().astype(int)\n",
    "    \n",
    "    # === TEXT LENGTH FEATURES ===\n",
    "    features['subject_length'] = df['subject'].fillna('').str.len()\n",
    "    features['body_length'] = df['body'].fillna('').str.len()\n",
    "    features['subject_word_count'] = df['subject'].fillna('').str.split().str.len().fillna(0)\n",
    "    features['body_word_count'] = df['body'].fillna('').str.split().str.len().fillna(0)\n",
    "    \n",
    "    # === URL FEATURES ===\n",
    "    # Convert urls to string first, handling NaN and lists\n",
    "    urls_str = df['urls'].fillna('').astype(str)\n",
    "    features['url_count'] = urls_str.str.count('http')\n",
    "    features['has_urls'] = (features['url_count'] > 0).astype(int)\n",
    "    features['suspicious_tld'] = urls_str.str.contains(\n",
    "        '.tk|.ml|.ga|.cf|.gq', \n",
    "        case=False, regex=True\n",
    "    ).astype(int)\n",
    "    \n",
    "    # === SUSPICIOUS PATTERNS ===\n",
    "    # Capital letters (shouting)\n",
    "    def caps_ratio(text):\n",
    "        text = str(text)\n",
    "        if len(text) == 0:\n",
    "            return 0\n",
    "        return sum(1 for c in text if c.isupper()) / len(text)\n",
    "    \n",
    "    features['subject_caps_ratio'] = df['subject'].fillna('').apply(caps_ratio)\n",
    "    \n",
    "    # Exclamation marks (count manually)\n",
    "    features['subject_exclamation'] = df['subject'].fillna('').apply(lambda x: str(x).count('!'))\n",
    "    features['body_exclamation'] = df['body'].fillna('').apply(lambda x: str(x).count('!'))\n",
    "    \n",
    "    # Dollar signs\n",
    "    features['has_dollar_sign'] = df['body'].fillna('').apply(lambda x: 1 if '$' in str(x) else 0)\n",
    "    \n",
    "    # Common phishing keywords\n",
    "    phishing_keywords = ['urgent', 'verify', 'account', 'suspended', 'click', \n",
    "                         'confirm', 'password', 'winner', 'prize', 'claim']\n",
    "    \n",
    "    def count_phishing_keywords(text):\n",
    "        text = str(text).lower()\n",
    "        return sum(keyword in text for keyword in phishing_keywords)\n",
    "    \n",
    "    # Create full_text if not exists\n",
    "    full_text = (df['subject'].fillna('') + ' ' + df['body'].fillna(''))\n",
    "    features['phishing_keyword_count'] = full_text.apply(count_phishing_keywords)\n",
    "    \n",
    "    # === TIME FEATURES (if date available) ===\n",
    "    if 'date' in df.columns and df['date'].notna().sum() > 0:\n",
    "        date_col = pd.to_datetime(df['date'], errors='coerce')\n",
    "        features['hour_of_day'] = date_col.dt.hour.fillna(-1).astype(int)\n",
    "        features['day_of_week'] = date_col.dt.dayofweek.fillna(-1).astype(int)\n",
    "        features['is_weekend'] = (date_col.dt.dayofweek >= 5).fillna(False).astype(int)\n",
    "    else:\n",
    "        # Add dummy columns if date not available\n",
    "        features['hour_of_day'] = -1\n",
    "        features['day_of_week'] = -1\n",
    "        features['is_weekend'] = 0\n",
    "    \n",
    "    # Fill any remaining NaN values\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract all engineered features\n",
    "X_engineered = extract_features(combined_df)\n",
    "\n",
    "# Check the results\n",
    "print(X_engineered.head())\n",
    "print(f\"\\nFeature shape: {X_engineered.shape}\")\n",
    "print(f\"\\nFeature columns: {X_engineered.columns.tolist()}\")\n",
    "print(f\"\\nAny NaN values: {X_engineered.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f74604bb-9b45-4e05-8bf0-ea56e9d63037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# Combine text features with engineered features\n",
    "if isinstance(X_text, np.ndarray):\n",
    "    # Dense array (embeddings)\n",
    "    X_combined = np.hstack([X_text, X_engineered.values])\n",
    "else:\n",
    "    # Sparse matrix (TF-IDF)\n",
    "    X_combined = hstack([X_text, X_engineered.values])\n",
    "\n",
    "y = combined_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1640b7-0156-4fbc-aade-c72d430866b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      7101\n",
      "           1       0.86      0.76      0.80      8235\n",
      "\n",
      "    accuracy                           0.80     15336\n",
      "   macro avg       0.81      0.81      0.80     15336\n",
      "weighted avg       0.81      0.80      0.80     15336\n",
      "\n",
      "[[6099 1002]\n",
      " [2014 6221]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "# OR\n",
    "# model = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "481077a8-aa3b-4572-83c1-b3a5c692de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['subject', 'body', 'label', 'sender', 'receiver', 'date', 'urls', 'source', 'subject_clean', 'body_clean', 'subject_length', 'body_length']\n",
      "\n",
      "Shape: (76677, 12)\n",
      "\n",
      "First few rows:\n",
      "                                             subject  \\\n",
      "0                          Never agree to be a loser   \n",
      "1                             Befriend Jenna Jameson   \n",
      "2                               CNN.com Daily Top 10   \n",
      "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4                         SpecialPricesPharmMoreinfo   \n",
      "\n",
      "                                                body  label  \\\n",
      "0  Buck up, your troubles caused by small dimensi...      1   \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1   \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1   \n",
      "3  Would anyone object to removing .so from this ...      0   \n",
      "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...      1   \n",
      "\n",
      "                                              sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "3                 Michael Parker <ivqrnai@pobox.com>   \n",
      "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
      "\n",
      "                                         receiver                       date  \\\n",
      "0                     user4@gvc.ceas-challenge.cc  2008-08-05 16:31:02-07:00   \n",
      "1                   user2.2@gvc.ceas-challenge.cc  2008-08-05 18:31:03-05:00   \n",
      "2                   user2.9@gvc.ceas-challenge.cc  2008-08-05 20:28:00-12:00   \n",
      "3  SpamAssassin Dev <xrh@spamassassin.apache.org>  2008-08-05 17:31:20-06:00   \n",
      "4                   user2.2@gvc.ceas-challenge.cc  2008-08-05 19:31:21-04:00   \n",
      "\n",
      "   urls   source                                      subject_clean  \\\n",
      "0   1.0  CEAS_08                          never agree to be a loser   \n",
      "1   1.0  CEAS_08                             befriend jenna jameson   \n",
      "2   1.0  CEAS_08                               cnn.com daily top 10   \n",
      "3   1.0  CEAS_08  re: svn commit: r619753 - in /spamassassin/tru...   \n",
      "4   1.0  CEAS_08                         specialpricespharmmoreinfo   \n",
      "\n",
      "                                          body_clean  subject_length  \\\n",
      "0  buck up, your troubles caused by small dimensi...              25   \n",
      "1  upgrade your sex and pleasures with these tech...              22   \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...              20   \n",
      "3  would anyone object to removing .so from this ...             150   \n",
      "4  welcomefastshippingcustomersupport http://7iwf...              26   \n",
      "\n",
      "   body_length  \n",
      "0          273  \n",
      "1           82  \n",
      "2         3918  \n",
      "3        24418  \n",
      "4          175  \n",
      "\n",
      "Data types:\n",
      "subject            object\n",
      "body               object\n",
      "label               int64\n",
      "sender             object\n",
      "receiver           object\n",
      "date               object\n",
      "urls              float64\n",
      "source             object\n",
      "subject_clean      object\n",
      "body_clean         object\n",
      "subject_length      int64\n",
      "body_length         int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "subject             331\n",
      "body                  0\n",
      "label                 0\n",
      "sender            32957\n",
      "receiver          34508\n",
      "date              33712\n",
      "urls              32626\n",
      "source                0\n",
      "subject_clean       332\n",
      "body_clean            3\n",
      "subject_length        0\n",
      "body_length           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned data\n",
    "df = pd.read_csv('cleaned_combined_emails.csv')\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Column names:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4fedf-bce7-4996-bc0c-96e5128a1aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
