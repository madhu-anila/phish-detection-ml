{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42acbec-060d-4afa-8e0d-91ca0abc534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\akash\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision tqdm scikit-learn pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71b3f88-cf9e-4973-be52-4210fa777d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c395e14-f023-4749-b070-bd717b79f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 37710 train names and 16456 test names\n",
      "Example train entries: ['3m10', '3m11', '3m12', '3m13', '3m14', '3m15', '3m16', '3m17']\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = r\"C:\\Users\\akash\\Desktop\\Email_Phishing_Detection\\openlogo\" \n",
    "\n",
    "IMG_DIR = os.path.join(BASE_DIR, \"JPEGImages\")\n",
    "CLASS_SEP_DIR = os.path.join(BASE_DIR, \"ImageSets\", \"class_sep\")\n",
    "TRAIN_TXT = os.path.join(CLASS_SEP_DIR, \"train.txt\")\n",
    "TEST_TXT  = os.path.join(CLASS_SEP_DIR, \"test.txt\")\n",
    "\n",
    "assert os.path.isdir(BASE_DIR), f\"BASE_DIR not found: {BASE_DIR}\"\n",
    "assert os.path.isdir(IMG_DIR), f\"JPEGImages folder not found under {BASE_DIR}\"\n",
    "assert os.path.exists(TRAIN_TXT), f\"train.txt not found: {TRAIN_TXT}\"\n",
    "assert os.path.exists(TEST_TXT), f\"test.txt not found: {TEST_TXT}\"\n",
    "\n",
    "# Read names (no extension in files)\n",
    "with open(TRAIN_TXT, 'r') as f:\n",
    "    train_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "with open(TEST_TXT, 'r') as f:\n",
    "    test_names = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "print(f\"Loaded {len(train_names)} train names and {len(test_names)} test names\")\n",
    "print(\"Example train entries:\", train_names[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b399ff-a505-470a-8524-86f5b6b0261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 18391, Val images: 4598, Test images: 12362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_names_unique = sorted(set(train_names))  # dedupe image IDs\n",
    "train_ids, val_ids = train_test_split(train_names_unique, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train images: {len(train_ids)}, Val images: {len(val_ids)}, Test images: {len(set(test_names))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dcdf992-9914-46ad-b750-2be357aed0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping train: 100%|██████████| 18391/18391 [26:04<00:00, 11.76it/s]\n",
      "Cropping val: 100%|██████████| 4598/4598 [07:20<00:00, 10.44it/s]\n",
      "Cropping test: 100%|██████████| 12362/12362 [12:36<00:00, 16.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from xml.etree import ElementTree as ET\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "ANN_DIR = os.path.join(BASE_DIR, \"Annotations\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"cropped_logos\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def parse_annotation(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    objs = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.find(\"name\").text\n",
    "        bb = obj.find(\"bndbox\")\n",
    "        xmin = int(bb.find(\"xmin\").text)\n",
    "        ymin = int(bb.find(\"ymin\").text)\n",
    "        xmax = int(bb.find(\"xmax\").text)\n",
    "        ymax = int(bb.find(\"ymax\").text)\n",
    "        objs.append({\"label\": name, \"bbox\": [xmin, ymin, xmax, ymax]})\n",
    "    return objs\n",
    "\n",
    "def crop_split(image_ids, split_name):\n",
    "    split_dir = os.path.join(OUT_DIR, split_name)\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "    for img_id in tqdm(image_ids, desc=f\"Cropping {split_name}\"):\n",
    "        img_path = os.path.join(IMG_DIR, img_id + \".jpg\")\n",
    "        ann_path = os.path.join(ANN_DIR, img_id + \".xml\")\n",
    "        if not (os.path.exists(img_path) and os.path.exists(ann_path)):\n",
    "            continue\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        for i, obj in enumerate(parse_annotation(ann_path)):\n",
    "            xmin, ymin, xmax, ymax = obj[\"bbox\"]\n",
    "            # basic safety clamp\n",
    "            w, h = img.size\n",
    "            xmin, ymin = max(0, xmin), max(0, ymin)\n",
    "            xmax, ymax = min(w, xmax), min(h, ymax)\n",
    "            if xmax <= xmin or ymax <= ymin:\n",
    "                continue\n",
    "            crop = img.crop((xmin, ymin, xmax, ymax))\n",
    "            class_dir = os.path.join(split_dir, obj[\"label\"])\n",
    "            os.makedirs(class_dir, exist_ok=True)\n",
    "            crop.save(os.path.join(class_dir, f\"{img_id}_{i}.jpg\"))\n",
    "\n",
    "# Run once\n",
    "crop_split(train_ids, \"train\")\n",
    "crop_split(val_ids,   \"val\")\n",
    "crop_split(set(test_names), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ed2dc-5886-437f-a674-6b8b0339db3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
